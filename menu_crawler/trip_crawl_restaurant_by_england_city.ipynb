{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = r\"F:\\Fork_git\\Labelling_Menu_Data\\menu_scraper\\webdriver\\chromedriver\\chromedriver.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Opening JSON file\n",
    "f = open('us_city_codes.json')\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "city_code = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'New York City New': '60763',\n",
       " 'Los Angeles': '32655',\n",
       " 'Chicago': '35805',\n",
       " 'Houston': '56003',\n",
       " 'Brooklyn New': '60827',\n",
       " 'San Francisco': '60713',\n",
       " 'Las Vegas': '45963',\n",
       " 'Philadelphia': '60795',\n",
       " 'San Diego': '60750',\n",
       " 'San Antonio': '60956',\n",
       " 'Miami': '34438',\n",
       " 'Dallas': '55711',\n",
       " 'Portland': '52024',\n",
       " 'Atlanta': '60898',\n",
       " 'Austin': '30196',\n",
       " 'Seattle': '60878',\n",
       " 'Orlando': '34515',\n",
       " 'Phoenix': '31310',\n",
       " 'Oahu': '29222',\n",
       " 'Denver': '33388'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "excluded_categories = {'Japanese', 'Singaporean', 'Indian', 'Korean', 'American', 'Type not available', 'Thai', 'Vietnamese', 'British', 'Italian'}\n",
    "\n",
    "# Update function to get links and names as per the provided HTML snippet\n",
    "def get_links_and_names(driver):\n",
    "    # Locate the entire restaurant divs\n",
    "    restaurant_divs = driver.find_elements(By.XPATH, '//div[@class=\"yJIls z y M0\"]')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Iterating through each restaurant div\n",
    "    for restaurant_div in restaurant_divs:\n",
    "        try:\n",
    "            # Finding name and link\n",
    "            name_link_elem = restaurant_div.find_element(By.XPATH, './/a[@href and @target=\"_blank\" and contains(@class, \"BMQDV\")]')\n",
    "            name = name_link_elem.text\n",
    "            link = name_link_elem.get_attribute('href')\n",
    "            \n",
    "            # Finding restaurant type\n",
    "            # Note: Might not be available for all entries, handle accordingly\n",
    "            elems = restaurant_div.find_elements(By.XPATH, './/span[@class=\"YECgr\"]')\n",
    "\n",
    "            restaurant_type = \"Type not available\"\n",
    "            price = \"Price not available\"\n",
    "\n",
    "\n",
    "\n",
    "            # Iterate through the found elements and check for the desired conditions\n",
    "            for elem in elems:\n",
    "                text = elem.text\n",
    "                \n",
    "                # Check if \"Chinese\" is in text, then it's a type\n",
    "                if any(symbol in text.lower() for symbol in ['chinese']):\n",
    "                    restaurant_type = text\n",
    "                # Check if any of the currency symbols are in text, then it's a price\n",
    "                elif any(symbol in text for symbol in [\"£\", \"$\", \"€\"]):  # you can add more currencies here\n",
    "                    price = text\n",
    "\n",
    "            categories = {category.strip() for category in restaurant_type.split(',')}        \n",
    "            if not categories.intersection(excluded_categories):\n",
    "                # Append the restaurant data to the list\n",
    "                data.append({\n",
    "                    'name': name, \n",
    "                    'link': link, \n",
    "                    'type': restaurant_type, \n",
    "                    'price': price\n",
    "                })\n",
    "        except Exception as e:\n",
    "            # Log or print exception info and continue with the next restaurant\n",
    "            print(f\"Skipping a restaurant due to an error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Update function to get page links as per the provided HTML snippet\n",
    "def get_page_links(driver):\n",
    "    # XPath to locate the next page button based on the provided HTML snippet\n",
    "    next_button = driver.find_elements(By.XPATH, '//a[@data-smoke-attr=\"pagination-next-arrow\"]')\n",
    "    return [btn.get_attribute('href') for btn in next_button]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login to the website and press Enter here to continue.\n",
      "Processing city: New York City New\n",
      "Accessing page 1 of New York City New\n",
      "Accessing page 2 of New York City New\n",
      "Accessing page 3 of New York City New\n",
      "Accessing page 4 of New York City New\n",
      "Accessing page 5 of New York City New\n",
      "Accessing page 6 of New York City New\n",
      "Accessing page 7 of New York City New\n",
      "Saved 0 total shop data to trip_advisor_new_york_city_new.json.\n",
      "Processing city: Los Angeles\n",
      "Accessing page 1 of Los Angeles\n",
      "Accessing page 2 of Los Angeles\n",
      "Accessing page 3 of Los Angeles\n",
      "Saved 0 total shop data to trip_advisor_los_angeles.json.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(all_shop_data, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_shop_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total shop data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Random delay between city crawls\u001b[39;00m\n\u001b[0;32m     64\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Base link template\n",
    "base_link_template = \"https://www.tripadvisor.co.uk/FindRestaurants?geo={}&cuisines=5379&establishmentTypes=10591&priceTypes=10954%2C10955&broadened=false\"\n",
    "\n",
    "# Selenium setup\n",
    "service = Service(executable_path=driver_path)\n",
    "options = Options()\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Retrieve the code for the first city\n",
    "first_city_code = list(city_code.values())[0]\n",
    "first_city_page = base_link_template.format(first_city_code)\n",
    "driver.get(first_city_page)\n",
    "\n",
    "# Wait for user to login\n",
    "print(\"Please login to the website and press Enter here to continue.\")\n",
    "input()\n",
    "\n",
    "# Loop through each city\n",
    "for city, code in city_code.items():\n",
    "    base_page = base_link_template.format(code)\n",
    "    filename = f'trip_advisor_{city.lower().replace(\" \", \"_\")}.json'\n",
    "\n",
    "    # Load existing data for the city\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            all_shop_data = json.load(f)\n",
    "    else:\n",
    "        all_shop_data = []\n",
    "\n",
    "    driver.get(base_page)\n",
    "    time.sleep(2 + random.random() * 5)  # Random delay\n",
    "\n",
    "    print(f\"Processing city: {city}\")\n",
    "\n",
    "    nav_links = get_page_links(driver)\n",
    "    continue_flag = True\n",
    "    page_count = 1\n",
    "\n",
    "    while continue_flag:\n",
    "        print(f'Accessing page {page_count} of {city}')\n",
    "        time.sleep(5 + random.random() * 5)  # Random delay\n",
    "        nav_links = get_page_links(driver)\n",
    "        shop_data = get_links_and_names(driver)\n",
    "\n",
    "        for shop in shop_data:\n",
    "            if shop not in all_shop_data:\n",
    "                all_shop_data.append(shop)\n",
    "\n",
    "        page_count += 1\n",
    "\n",
    "        if len(nav_links) < 1:\n",
    "            continue_flag = False\n",
    "        else:\n",
    "            driver.get(nav_links[0])\n",
    "\n",
    "    # Dump the data into the city-specific JSON file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_shop_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Saved {len(all_shop_data)} total shop data to {filename}.\")\n",
    "\n",
    "    time.sleep(5 + random.random() * 5)  # Random delay between city crawls\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_data = get_links_and_names(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sleep(min_time=1, max_time=3):\n",
    "    time.sleep(random.uniform(min_time, max_time))\n",
    "\n",
    "# Define a function to download and save images from URLs\n",
    "def download_image(img_url, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        urllib.request.urlretrieve(img_url, save_path)\n",
    "        print(f'Saved image: {save_path}')\n",
    "\n",
    "# Define a function to get image URLs\n",
    "def get_image_urls(driver):\n",
    "    elems = driver.find_elements(By.XPATH, '//div[@class=\"img\"]/a/img')\n",
    "    return [elem.get_attribute('src') for elem in elems]\n",
    "\n",
    "def get_high_res_image_url(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"main-pic-stage\"]/img')))\n",
    "        elem = driver.find_element(By.XPATH, '//div[@class=\"main-pic-stage\"]/img')\n",
    "        return elem.get_attribute('src')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def go_to_next_image(driver):\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//a[@class=\"next J_pic-next\"]')\n",
    "        ActionChains(driver).click(next_button).perform()\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
