{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = r\"F:\\Fork_git\\Labelling_Menu_Data\\menu_scraper\\webdriver\\chromedriver\\chromedriver.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Opening JSON file\n",
    "f = open('us_city_codes.json')\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "city_code = json.load(f)\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'New York City New': '60763',\n",
       " 'Los Angeles': '32655',\n",
       " 'Chicago': '35805',\n",
       " 'Houston': '56003',\n",
       " 'Brooklyn New': '60827',\n",
       " 'San Francisco': '60713',\n",
       " 'Las Vegas': '45963',\n",
       " 'Philadelphia': '60795',\n",
       " 'San Diego': '60750',\n",
       " 'San Antonio': '60956',\n",
       " 'Miami': '34438',\n",
       " 'Dallas': '55711',\n",
       " 'Portland': '52024',\n",
       " 'Atlanta': '60898',\n",
       " 'Austin': '30196',\n",
       " 'Seattle': '60878',\n",
       " 'Orlando': '34515',\n",
       " 'Phoenix': '31310',\n",
       " 'Oahu': '29222',\n",
       " 'Denver': '33388'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "excluded_categories = {'Japanese', 'Singaporean', 'Indian', 'Korean', 'American', 'Type not available', 'Thai', 'Vietnamese', 'British', 'Italian'}\n",
    "\n",
    "# Update function to get links and names as per the provided HTML snippet\n",
    "def get_links_and_names(driver):\n",
    "    # Locate the entire restaurant divs\n",
    "    restaurant_divs = driver.find_elements(By.XPATH, '//div[@class=\"vIjFZ Gi o VOEhq\"]')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Iterating through each restaurant div\n",
    "    for restaurant_div in restaurant_divs:\n",
    "        try:\n",
    "            # Finding name and link\n",
    "            name_link_elem = restaurant_div.find_element(By.XPATH, './/a[@href and @target=\"_blank\" and contains(@class, \"BMQDV\")]')\n",
    "            name = name_link_elem.text\n",
    "            link = name_link_elem.get_attribute('href')\n",
    "            \n",
    "            # Finding restaurant type\n",
    "            # Note: Might not be available for all entries, handle accordingly\n",
    "            elems = restaurant_div.find_elements(By.XPATH, './/span[@class=\"YECgr\"]')\n",
    "\n",
    "            restaurant_type = \"Type not available\"\n",
    "            price = \"Price not available\"\n",
    "\n",
    "\n",
    "\n",
    "            # Iterate through the found elements and check for the desired conditions\n",
    "            for elem in elems:\n",
    "                text = elem.text\n",
    "                \n",
    "                # Check if \"Chinese\" is in text, then it's a type\n",
    "                if any(symbol in text.lower() for symbol in ['chinese']):\n",
    "                    restaurant_type = text\n",
    "                # Check if any of the currency symbols are in text, then it's a price\n",
    "                elif any(symbol in text for symbol in [\"£\", \"$\", \"€\"]):  # you can add more currencies here\n",
    "                    price = text\n",
    "\n",
    "            categories = {category.strip() for category in restaurant_type.split(',')}        \n",
    "            if not categories.intersection(excluded_categories):\n",
    "                # Append the restaurant data to the list\n",
    "                data.append({\n",
    "                    'name': name, \n",
    "                    'link': link, \n",
    "                    'type': restaurant_type, \n",
    "                    'price': price\n",
    "                })\n",
    "        except Exception as e:\n",
    "            # Log or print exception info and continue with the next restaurant\n",
    "            print(f\"Skipping a restaurant due to an error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Update function to get page links as per the provided HTML snippet\n",
    "def get_page_links(driver):\n",
    "    # XPath to locate the next page button based on the provided HTML snippet\n",
    "    next_button = driver.find_elements(By.XPATH, '//a[@data-smoke-attr=\"pagination-next-arrow\"]')\n",
    "    return [btn.get_attribute('href') for btn in next_button]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login to the website and press Enter here to continue.\n",
      "Processing city: New York City New\n",
      "Accessing page 1 of New York City New\n",
      "Accessing page 2 of New York City New\n",
      "Accessing page 3 of New York City New\n",
      "Accessing page 4 of New York City New\n",
      "Accessing page 5 of New York City New\n",
      "Accessing page 6 of New York City New\n",
      "Accessing page 7 of New York City New\n",
      "Saved 168 total shop data to us_tripadvisoor/trip_advisor_new_york_city_new.json.\n",
      "Processing city: Los Angeles\n",
      "Accessing page 1 of Los Angeles\n",
      "Accessing page 2 of Los Angeles\n",
      "Accessing page 3 of Los Angeles\n",
      "Saved 71 total shop data to us_tripadvisoor/trip_advisor_los_angeles.json.\n",
      "Processing city: Chicago\n",
      "Accessing page 1 of Chicago\n",
      "Accessing page 2 of Chicago\n",
      "Accessing page 3 of Chicago\n",
      "Saved 66 total shop data to us_tripadvisoor/trip_advisor_chicago.json.\n",
      "Processing city: Houston\n",
      "Accessing page 1 of Houston\n",
      "Accessing page 2 of Houston\n",
      "Accessing page 3 of Houston\n",
      "Accessing page 4 of Houston\n",
      "Saved 86 total shop data to us_tripadvisoor/trip_advisor_houston.json.\n",
      "Processing city: Brooklyn New\n",
      "Accessing page 1 of Brooklyn New\n",
      "Accessing page 2 of Brooklyn New\n",
      "Saved 34 total shop data to us_tripadvisoor/trip_advisor_brooklyn_new.json.\n",
      "Processing city: San Francisco\n",
      "Accessing page 1 of San Francisco\n",
      "Accessing page 2 of San Francisco\n",
      "Accessing page 3 of San Francisco\n",
      "Accessing page 4 of San Francisco\n",
      "Saved 94 total shop data to us_tripadvisoor/trip_advisor_san_francisco.json.\n",
      "Processing city: Las Vegas\n",
      "Accessing page 1 of Las Vegas\n",
      "Accessing page 2 of Las Vegas\n",
      "Accessing page 3 of Las Vegas\n",
      "Saved 75 total shop data to us_tripadvisoor/trip_advisor_las_vegas.json.\n",
      "Processing city: Philadelphia\n",
      "Accessing page 1 of Philadelphia\n",
      "Accessing page 2 of Philadelphia\n",
      "Saved 48 total shop data to us_tripadvisoor/trip_advisor_philadelphia.json.\n",
      "Processing city: San Diego\n",
      "Accessing page 1 of San Diego\n",
      "Accessing page 2 of San Diego\n",
      "Saved 31 total shop data to us_tripadvisoor/trip_advisor_san_diego.json.\n",
      "Processing city: San Antonio\n",
      "Accessing page 1 of San Antonio\n",
      "Accessing page 2 of San Antonio\n",
      "Saved 41 total shop data to us_tripadvisoor/trip_advisor_san_antonio.json.\n",
      "Processing city: Miami\n",
      "Accessing page 1 of Miami\n",
      "Accessing page 2 of Miami\n",
      "Saved 33 total shop data to us_tripadvisoor/trip_advisor_miami.json.\n",
      "Processing city: Dallas\n",
      "Accessing page 1 of Dallas\n",
      "Saved 14 total shop data to us_tripadvisoor/trip_advisor_dallas.json.\n",
      "Processing city: Portland\n",
      "Accessing page 1 of Portland\n",
      "Accessing page 2 of Portland\n",
      "Saved 34 total shop data to us_tripadvisoor/trip_advisor_portland.json.\n",
      "Processing city: Atlanta\n",
      "Accessing page 1 of Atlanta\n",
      "Accessing page 2 of Atlanta\n",
      "Saved 28 total shop data to us_tripadvisoor/trip_advisor_atlanta.json.\n",
      "Processing city: Austin\n",
      "Accessing page 1 of Austin\n",
      "Accessing page 2 of Austin\n",
      "Saved 40 total shop data to us_tripadvisoor/trip_advisor_austin.json.\n",
      "Processing city: Seattle\n",
      "Accessing page 1 of Seattle\n",
      "Accessing page 2 of Seattle\n",
      "Saved 45 total shop data to us_tripadvisoor/trip_advisor_seattle.json.\n",
      "Processing city: Orlando\n",
      "Accessing page 1 of Orlando\n",
      "Accessing page 2 of Orlando\n",
      "Saved 31 total shop data to us_tripadvisoor/trip_advisor_orlando.json.\n",
      "Processing city: Phoenix\n",
      "Accessing page 1 of Phoenix\n",
      "Saved 27 total shop data to us_tripadvisoor/trip_advisor_phoenix.json.\n",
      "Processing city: Oahu\n",
      "Accessing page 1 of Oahu\n",
      "Accessing page 2 of Oahu\n",
      "Saved 46 total shop data to us_tripadvisoor/trip_advisor_oahu.json.\n",
      "Processing city: Denver\n",
      "Accessing page 1 of Denver\n",
      "Accessing page 2 of Denver\n",
      "Saved 35 total shop data to us_tripadvisoor/trip_advisor_denver.json.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Base link template\n",
    "base_link_template = \"https://www.tripadvisor.co.uk/FindRestaurants?geo={}&cuisines=5379&establishmentTypes=10591&priceTypes=10954%2C10955&broadened=false\"\n",
    "\n",
    "# Selenium setup\n",
    "service = Service(executable_path=driver_path)\n",
    "options = Options()\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Retrieve the code for the first city\n",
    "first_city_code = list(city_code.values())[0]\n",
    "first_city_page = base_link_template.format(first_city_code)\n",
    "driver.get(first_city_page)\n",
    "\n",
    "# Wait for user to login\n",
    "print(\"Please login to the website and press Enter here to continue.\")\n",
    "input()\n",
    "\n",
    "# Loop through each city\n",
    "for city, code in city_code.items():\n",
    "    base_page = base_link_template.format(code)\n",
    "    filename = f'us_tripadvisoor/trip_advisor_{city.lower().replace(\" \", \"_\")}.json'\n",
    "\n",
    "    # Load existing data for the city\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            all_shop_data = json.load(f)\n",
    "    else:\n",
    "        all_shop_data = []\n",
    "\n",
    "    driver.get(base_page)\n",
    "    time.sleep(2 + random.random() * 5)  # Random delay\n",
    "\n",
    "    print(f\"Processing city: {city}\")\n",
    "\n",
    "    nav_links = get_page_links(driver)\n",
    "    continue_flag = True\n",
    "    page_count = 1\n",
    "\n",
    "    while continue_flag:\n",
    "        print(f'Accessing page {page_count} of {city}')\n",
    "        time.sleep(5 + random.random() * 5)  # Random delay\n",
    "        nav_links = get_page_links(driver)\n",
    "        shop_data = get_links_and_names(driver)\n",
    "\n",
    "        for shop in shop_data:\n",
    "            if shop not in all_shop_data:\n",
    "                all_shop_data.append(shop)\n",
    "\n",
    "        page_count += 1\n",
    "\n",
    "        if len(nav_links) < 1:\n",
    "            continue_flag = False\n",
    "        else:\n",
    "            driver.get(nav_links[0])\n",
    "\n",
    "    # Dump the data into the city-specific JSON file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_shop_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "    print(f\"Saved {len(all_shop_data)} total shop data to {filename}.\")\n",
    "\n",
    "    time.sleep(5 + random.random() * 5)  # Random delay between city crawls\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_data = get_links_and_names(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '61. New Kamara Restaurant',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d19859331-Reviews-New_Kamara_Restaurant-Los_Angeles_California.html',\n",
       "  'type': 'Chinese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '63. Kung Pao Bistro',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d468653-Reviews-Kung_Pao_Bistro-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Cantonese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '64. China Star',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d509379-Reviews-China_Star-Los_Angeles_California.html',\n",
       "  'type': 'Chinese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '65. New Flavors',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d5453267-Reviews-New_Flavors-Los_Angeles_California.html',\n",
       "  'type': 'Chinese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '66. Western Doma Noodles',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d525985-Reviews-Western_Doma_Noodles-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '67. Kolah Farangi',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d3295058-Reviews-Kolah_Farangi-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '68. Jin China Bistro',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d14262901-Reviews-Jin_China_Bistro-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '70. Mandarin Island',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d5082835-Reviews-Mandarin_Island-Los_Angeles_California.html',\n",
       "  'type': 'Chinese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '72. Chin Chin',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d468465-Reviews-Chin_Chin-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '74. Hop Li',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d1208590-Reviews-Hop_Li-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '75. Chin Chin',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d348170-Reviews-Chin_Chin-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '76. Feng Mao Mutton Kabab',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d1553950-Reviews-Feng_Mao_Mutton_Kabab-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '77. Ocha Classic',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d371840-Reviews-Ocha_Classic-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': \"78. Tam's Garden Chinese Restaurant\",\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d477396-Reviews-Tam_s_Garden_Chinese_Restaurant-Los_Angeles_California.html',\n",
       "  'type': 'Chinese',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '79. Gengis Khan',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d21268314-Reviews-Gengis_Khan-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Fast food',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '84. Thai Angel',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d10764341-Reviews-Thai_Angel-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Bar',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '85. Woon',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d17813064-Reviews-Woon-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Asian',\n",
       "  'price': '££ - £££'},\n",
       " {'name': '86. Mee Dee Thai Kitchen',\n",
       "  'link': 'https://www.tripadvisor.co.uk/Restaurant_Review-g32655-d23144829-Reviews-Mee_Dee_Thai_Kitchen-Los_Angeles_California.html',\n",
       "  'type': 'Chinese, Philippine',\n",
       "  'price': '££ - £££'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sleep(min_time=1, max_time=3):\n",
    "    time.sleep(random.uniform(min_time, max_time))\n",
    "\n",
    "# Define a function to download and save images from URLs\n",
    "def download_image(img_url, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        urllib.request.urlretrieve(img_url, save_path)\n",
    "        print(f'Saved image: {save_path}')\n",
    "\n",
    "# Define a function to get image URLs\n",
    "def get_image_urls(driver):\n",
    "    elems = driver.find_elements(By.XPATH, '//div[@class=\"img\"]/a/img')\n",
    "    return [elem.get_attribute('src') for elem in elems]\n",
    "\n",
    "def get_high_res_image_url(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"main-pic-stage\"]/img')))\n",
    "        elem = driver.find_element(By.XPATH, '//div[@class=\"main-pic-stage\"]/img')\n",
    "        return elem.get_attribute('src')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def go_to_next_image(driver):\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//a[@class=\"next J_pic-next\"]')\n",
    "        ActionChains(driver).click(next_button).perform()\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
